"""Siyadah Ops AI - Ø§Ù„Ù†Ø³Ø®Ø© Ù…Ø¹ OpenAI Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime
import structlog
import json
import random
import asyncio
import openai
import os
from dotenv import load_dotenv

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv("env")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ logging
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Ø¥Ø¹Ø¯Ø§Ø¯ OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
app = FastAPI(
    title="Siyadah Ops AI",
    description="Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø°ÙƒÙŠ Ù„Ø´Ø±ÙƒØ© Ø¯10",
    version="1.0.0"
)

# Ø¥Ø¹Ø¯Ø§Ø¯ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† MongoDB)
tasks_storage = []
kpis_storage = []
prompts_storage = {
    "coach": {
        "system": "Ø£Ù†Øª ÙƒÙˆØªØ´ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­ÙÙŠØ² Ù…ÙˆØ¸ÙÙŠ Ø´Ø±ÙƒØ© Ø¯10 Ù„Ù„ØªØ³ÙˆÙŠÙ‚ Ø§Ù„Ø±Ù‚Ù…ÙŠ. Ø´Ø®ØµÙŠØªÙƒ ÙˆØ¯ÙˆØ¯Ø© ÙˆÙ…Ø­ØªØ±ÙØ©ØŒ ØªØªÙƒÙ„Ù… Ø¨Ù„Ù‡Ø¬Ø© Ø³Ø¹ÙˆØ¯ÙŠØ© Ø®ÙÙŠÙØ©. Ø®Ø¨Ø±ØªÙƒ ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ© ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ù‡Ø¯Ø§Ù. Ø§ÙƒØªØ¨ â‰¤3 Ø¬Ù…Ù„ ÙÙ‚Ø· ÙˆØ§Ø³ØªØ®Ø¯Ù… Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØ§Ø­Ø¯ Ø£Ùˆ Ø§Ø«Ù†ÙŠÙ†. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø®Ø·ÙˆØ© ÙˆØ§Ø­Ø¯Ø© ÙˆØ§Ø¶Ø­Ø© ÙŠÙ…ÙƒÙ† ØªÙ†ÙÙŠØ°Ù‡Ø§ Ø§Ù„ÙŠÙˆÙ…. ØªØ¬Ù†Ø¨ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ø¯ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± ÙˆØ§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„ÙˆÙ„.",
        "user_template": "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¸Ù: Ø§Ù„Ø§Ø³Ù…: {name}, Ø§Ù„Ù‚Ø³Ù…: {department}, Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡: {performance_level}, Ø§Ù„Ù…Ù„Ø®Øµ: {summary}, Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ: {current_time}, Ø§Ù„ÙŠÙˆÙ…: {current_day}"
    },
    "orchestrator": {
        "system": "Ø£Ù†Øª Ù…Ù†Ø³Ù‚ Ù…Ø´Ø§Ø±ÙŠØ¹ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªÙÙƒÙŠÙƒ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¥Ù„Ù‰ Ù…Ù‡Ø§Ù… Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ†ÙÙŠØ°. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 6 Ù…Ù‡Ø§Ù… ÙÙŠ Ø§Ù„ØªÙÙƒÙŠÙƒ Ø§Ù„Ø£ÙˆÙ„. ÙƒÙ„ Ù…Ù‡Ù…Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¥Ù†Ø¬Ø§Ø² Ø®Ù„Ø§Ù„ 1-7 Ø£ÙŠØ§Ù…. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø­Ø¯Ø¯Ø© Ù„Ù„Ù…Ù‡Ø§Ù…. Ø±Ø§Ø¹ÙŠ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ (Ù…Ù‡Ù…Ø© Ø£ Ù‚Ø¨Ù„ Ù…Ù‡Ù…Ø© Ø¨).",
        "user_template": "Ø§Ù„Ù‡Ø¯Ù/Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {goal_text}. Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©: Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ: {timeline}, Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©: {available_departments}"
    }
}

# Schemas
class TaskCreate(BaseModel):
    title: str
    assignee_email: str
    due_date: Optional[str] = None
    description: Optional[str] = None

class CoachPing(BaseModel):
    user_email: str
    department: str
    summary: Optional[str] = None

class KPIUpsert(BaseModel):
    user_email: str
    month: str
    target: int
    actual: int

class SlackMock(BaseModel):
    text: str
    user: str

class PromptUpdate(BaseModel):
    template: str
    variables: Optional[Dict[str, Any]] = {}

class GoalExpand(BaseModel):
    goal_text: str
    timeline: Optional[str] = "Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ†"
    available_departments: Optional[str] = "sales,marketing,tech,sondos"

# Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡
PERFORMANCE_TEMPLATES = {
    "excellent": [
        "Ù…Ø¨Ø±ÙˆÙƒ! Ø£Ø¯Ø§Ø¤Ùƒ Ø±Ø§Ø¦Ø¹ ğŸŒŸ Ø§Ø³ØªÙ…Ø± Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù…Ø³ØªÙˆÙ‰",
        "Ø¥Ù†Ø¬Ø§Ø² Ù…Ù…ØªØ§Ø²! ğŸš€ Ø£Ù†Øª Ù…Ø«Ø§Ù„ ÙŠÙØ­ØªØ°Ù‰ Ø¨Ù‡",
        "Ø£Ø¯Ø§Ø¡ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ! âœ¨ ÙˆØ§ØµÙ„ Ø§Ù„ØªÙ…ÙŠØ²"
    ],
    "good": [
        "Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯! ğŸ‘ Ø®Ø·ÙˆØ© Ø¨Ø³ÙŠØ·Ø© Ø¥Ø¶Ø§ÙÙŠØ© ÙˆØªÙˆØµÙ„ Ù„Ù„Ù‡Ø¯Ù",
        "ØªÙ‚Ø¯Ù… Ù…Ù„Ø­ÙˆØ¸! ğŸ“ˆ Ø±ÙƒØ² Ø¹Ù„Ù‰ {focus_area} Ø§Ù„ÙŠÙˆÙ…",
        "ÙÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø§Ù„ØµØ­ÙŠØ­! ğŸ¯ ÙˆØ§ØµÙ„ Ø¨Ù†ÙØ³ Ø§Ù„ÙˆØªÙŠØ±Ø©"
    ],
    "needs_improvement": [
        "Ù„Ø§ Ø¨Ø£Ø³ØŒ Ø§Ù„Ù‡Ø¯Ù Ù‚Ø±ÙŠØ¨! ğŸ’ª Ø±ÙƒØ² Ø¹Ù„Ù‰ {action} Ø§Ù„ÙŠÙˆÙ…",
        "ØªØ­Ø¯ÙŠ Ø¨Ø³ÙŠØ·! ğŸ”¥ Ø¬Ø±Ø¨ {suggestion} ÙˆØ´ÙˆÙ Ø§Ù„ÙØ±Ù‚",
        "Ø®Ø·ÙˆØ© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·! âš¡ {next_step} ÙˆØªÙƒÙˆÙ† ÙÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©"
    ],
    "critical": [
        "ÙˆÙ‚Øª Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø¬Ø§Ø¯! ğŸ¯ Ù†Ø±ÙƒØ² Ø¹Ù„Ù‰ {priority} ÙÙˆØ±Ø§Ù‹",
        "ØªØ­Ø¯ÙŠ ÙƒØ¨ÙŠØ± ÙŠØ­ØªØ§Ø¬ Ø­Ù„ Ø³Ø±ÙŠØ¹! âš ï¸ {urgent_action}",
        "ÙˆØ¶Ø¹ Ø·ÙˆØ§Ø±Ø¦! ğŸš¨ Ø§ØªØµÙ„ Ø¨Ù…Ø¯ÙŠØ±Ùƒ ÙÙˆØ±Ø§Ù‹ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©"
    ]
}

# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
DEPARTMENT_VARIABLES = {
    "sales": {
        "focus_area": "Ø¥Ù‚ÙØ§Ù„ ØµÙÙ‚Ø© ÙˆØ§Ø­Ø¯Ø©",
        "action": "Ø§ØªØµØ§Ù„ ÙˆØ§Ø­Ø¯ Ù…Ù‡Ù…",
        "suggestion": "Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ù‡ØªÙ…ÙŠÙ†",
        "next_step": "Ù‚ÙÙ„ Ù…ÙƒØ³Ø¨ ØµØºÙŠØ±",
        "priority": "Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø³Ø§Ø®Ù†ÙŠÙ†",
        "urgent_action": "Ø±Ø§Ø¬Ø¹ pipeline Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª"
    },
    "marketing": {
        "focus_area": "Ù‚Ø·Ø¹Ø© Ù…Ø­ØªÙˆÙ‰ Ø¬Ø¯ÙŠØ¯Ø©", 
        "action": "Ù…Ù†Ø´ÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ ÙˆØ§Ø­Ø¯",
        "suggestion": "ØªØ­Ù„ÙŠÙ„ Ù…Ù†Ø§ÙØ³ ÙˆØ§Ø­Ø¯",
        "next_step": "Ø­Ù…Ù„Ø© ØµØºÙŠØ±Ø© Ù…Ø³ØªÙ‡Ø¯ÙØ©",
        "priority": "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡",
        "urgent_action": "Ø±Ø§Ø¬Ø¹ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø­ØªÙˆÙ‰"
    },
    "tech": {
        "focus_area": "Ø­Ù„ ØªØ°ÙƒØ±Ø© ÙˆØ§Ø­Ø¯Ø©",
        "action": "Ù…Ø±Ø§Ø¬Ø¹Ø© ÙƒÙˆØ¯ ÙˆØ§Ø­Ø¯Ø©", 
        "suggestion": "ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ ØµØºÙŠØ±",
        "next_step": "PR Ø£Ùˆ merge ÙˆØ§Ø­Ø¯",
        "priority": "Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø­Ø±Ø¬Ø©",
        "urgent_action": "Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡"
    },
    "sondos": {
        "focus_area": "Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø¹Ù…ÙŠÙ„ ÙˆØ§Ø­Ø¯",
        "action": "ØªØ·ÙˆÙŠØ± Ù…ÙŠØ²Ø© ØµØºÙŠØ±Ø©",
        "suggestion": "ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯", 
        "next_step": "ØªØ­Ø³ÙŠÙ† Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©",
        "priority": "Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ù„Ø­Ø©",
        "urgent_action": "Ø±Ø§Ø¬Ø¹ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"
    }
}

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
async def call_openai(messages: list, max_tokens: int = 200) -> Optional[str]:
    """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = await client.chat.completions.acreate(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"OpenAI error: {e}")
        return None

# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
@app.get("/")
async def root():
    return {"message": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Siyadah Ops AI ğŸš€ - Ø§Ù„Ù†Ø³Ø®Ø© Ù…Ø¹ OpenAI Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ"}

@app.get("/healthz")
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    return {"status": "ok", "message": "Siyadah Ops AI is running", "openai": "connected", "mongodb": "in-memory"}

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù‡Ø§Ù…
@app.post("/tasks")
async def create_task(task_data: TaskCreate):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
    task = {
        "id": f"task_{len(tasks_storage) + 1}",
        "title": task_data.title,
        "assignee_email": task_data.assignee_email,
        "due_date": task_data.due_date or "2025-09-20",
        "status": "open",
        "source": "api",
        "created_at": datetime.now().isoformat(),
        "description": task_data.description
    }
    tasks_storage.append(task)
    
    logger.info(f"Task created: {task['id']}")
    return task

@app.get("/tasks")
async def get_tasks(assignee_email: Optional[str] = None):
    """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù‡Ø§Ù…"""
    if assignee_email:
        filtered_tasks = [t for t in tasks_storage if t["assignee_email"] == assignee_email]
        return filtered_tasks
    return tasks_storage

# Ù…Ø³Ø§Ø±Ø§Øª KPIs
@app.post("/kpis/upsert")
async def upsert_kpi(kpi_data: KPIUpsert):
    """ØªØ­Ø¯ÙŠØ« Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ KPI"""
    target = kpi_data.target
    actual = kpi_data.actual
    drift = max(0.0, (target - actual) / target) if target > 0 else 0.0
    
    performance_level = "excellent" if drift < 0.15 else "good" if drift < 0.25 else "needs_improvement" if drift < 0.35 else "critical"
    
    kpi = {
        "id": f"kpi_{len(kpis_storage) + 1}",
        "user_email": kpi_data.user_email,
        "month": kpi_data.month,
        "target": target,
        "actual": actual,
        "drift": drift,
        "performance_level": performance_level,
        "updated_at": datetime.now().isoformat()
    }
    
    # ØªØ­Ø¯ÙŠØ« Ø£Ùˆ Ø¥Ø¶Ø§ÙØ©
    existing = next((k for k in kpis_storage if k["user_email"] == kpi_data.user_email and k["month"] == kpi_data.month), None)
    if existing:
        existing.update(kpi)
        kpi = existing
    else:
        kpis_storage.append(kpi)
    
    logger.info(f"KPI upserted: {kpi['id']}")
    return kpi

@app.get("/kpis/performance/{user_email}")
async def get_user_performance(user_email: str):
    """Ø¬Ù„Ø¨ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    user_kpis = [k for k in kpis_storage if k["user_email"] == user_email]
    if not user_kpis:
        return {
            "user_email": user_email,
            "department": "general",
            "drift": 0.0,
            "performance_level": "no_data"
        }
    
    latest_kpi = max(user_kpis, key=lambda x: x["updated_at"])
    return latest_kpi

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ÙƒÙˆØªØ´ Ù…Ø¹ OpenAI Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
@app.post("/coach/ping")
async def coach_ping(ping_data: CoachPing):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© ØªØ­ÙÙŠØ² Ù…Ù† Ø§Ù„ÙƒÙˆØªØ´ Ø§Ù„Ø°ÙƒÙŠ Ù…Ø¹ OpenAI"""
    department = ping_data.department
    user_name = ping_data.user_email.split("@")[0]
    
    # Ø¬Ù„Ø¨ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    performance_data = await get_user_performance(ping_data.user_email)
    performance_level = performance_data.get("performance_level", "good")
    drift = performance_data.get("drift", 0.2)
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
    if performance_level == "excellent" or drift < 0.15:
        return {
            "message": "",
            "performance_level": performance_level,
            "should_send": False,
            "reason": "Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø² - Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ø±Ø³Ø§Ù„Ø©"
        }
    
    # Ø¬Ù„Ø¨ Ø§Ù„Ù€ prompts Ø§Ù„Ù…Ø±Ù†Ø©
    system_prompt = prompts_storage["coach"]["system"]
    user_template = prompts_storage["coach"]["user_template"]
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
    variables = {
        "name": user_name,
        "department": department,
        "performance_level": performance_level,
        "summary": ping_data.summary or "Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯",
        "current_time": datetime.now().strftime("%H:%M"),
        "current_day": "Ø§Ù„ÙŠÙˆÙ…"
    }
    
    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ù„Ø¨
    user_prompt = user_template.format(**variables)
    
    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    ai_response = await call_openai(messages)
    
    # Ø¥Ø°Ø§ ÙØ´Ù„ AIØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
    if not ai_response:
        templates = PERFORMANCE_TEMPLATES.get(performance_level, PERFORMANCE_TEMPLATES["good"])
        template = random.choice(templates)
        dept_vars = DEPARTMENT_VARIABLES.get(department, DEPARTMENT_VARIABLES["sales"])
        try:
            ai_response = template.format(**dept_vars)
        except KeyError:
            ai_response = f"Ø£Ø¯Ø§Ø¤Ùƒ Ø¬ÙŠØ¯ ÙŠØ§ {user_name}! ğŸŒŸ Ø§Ø³ØªÙ…Ø± Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ ÙÙŠ Ù‚Ø³Ù… {department}"
    
    logger.info(f"Coach message generated for {user_name}: {performance_level}")
    
    return {
        "message": ai_response,
        "performance_level": performance_level,
        "should_send": True,
        "drift": drift,
        "ai_source": "openai" if ai_response else "fallback"
    }

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù€ Prompts
@app.get("/prompts/{agent_type}")
async def get_agent_prompts(agent_type: str):
    """Ø¹Ø±Ø¶ prompts Ù„Ù„Ù€ agent"""
    if agent_type not in prompts_storage:
        raise HTTPException(status_code=404, detail="Agent type not found")
    
    prompts = []
    for prompt_name, template in prompts_storage[agent_type].items():
        prompts.append({
            "id": f"{agent_type}_{prompt_name}",
            "agent_type": agent_type,
            "prompt_name": prompt_name,
            "template": template,
            "variables": {
                "{name}": "Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¸Ù",
                "{department}": "Ø§Ù„Ù‚Ø³Ù…",
                "{performance_level}": "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ø¯Ø§Ø¡",
                "{summary}": "Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡"
            },
            "is_active": True,
            "updated_at": datetime.now().isoformat()
        })
    
    return prompts

@app.put("/prompts/{agent_type}/{prompt_name}")
async def update_prompt(agent_type: str, prompt_name: str, prompt_data: PromptUpdate):
    """ØªØ­Ø¯ÙŠØ« prompt"""
    if agent_type not in prompts_storage:
        raise HTTPException(status_code=404, detail="Agent type not found")
    
    if prompt_name not in prompts_storage[agent_type]:
        raise HTTPException(status_code=404, detail="Prompt name not found")
    
    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ prompt
    prompts_storage[agent_type][prompt_name] = prompt_data.template
    
    logger.info(f"Prompt updated: {agent_type}/{prompt_name}")
    
    return {
        "id": f"{agent_type}_{prompt_name}",
        "agent_type": agent_type,
        "prompt_name": prompt_name,
        "template": prompt_data.template,
        "variables": prompt_data.variables or {},
        "is_active": True,
        "updated_at": datetime.now().isoformat(),
        "message": "ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ prompt Ø¨Ù†Ø¬Ø§Ø­"
    }

# Ù…Ø³Ø§Ø± ØªÙÙƒÙŠÙƒ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ù…Ø¹ OpenAI
@app.post("/orchestrator/expand")
async def expand_goal(goal_data: GoalExpand):
    """ØªÙÙƒÙŠÙƒ Ø§Ù„Ù‡Ø¯Ù Ø¥Ù„Ù‰ Ù…Ù‡Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI"""
    try:
        # Ø¬Ù„Ø¨ Ø§Ù„Ù€ prompts Ø§Ù„Ù…Ø±Ù†Ø©
        system_prompt = prompts_storage["orchestrator"]["system"]
        user_template = prompts_storage["orchestrator"]["user_template"]
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª
        variables = {
            "goal_text": goal_data.goal_text,
            "timeline": goal_data.timeline,
            "available_departments": goal_data.available_departments
        }
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù‚Ø§Ù„Ø¨
        user_prompt = user_template.format(**variables)
        
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        ai_response = await call_openai(messages, max_tokens=500)
        
        # Ø¥Ø°Ø§ ÙØ´Ù„ AIØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        if not ai_response:
            ai_response = f"""
Ù…Ø´Ø±ÙˆØ¹: {goal_data.goal_text}
Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: {goal_data.timeline}

Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:
1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª (2 Ø£ÙŠØ§Ù…)
2. Ø§Ù„ØªØ®Ø·ÙŠØ· ÙˆØ§Ù„ØªØµÙ…ÙŠÙ… (3 Ø£ÙŠØ§Ù…)  
3. Ø§Ù„ØªÙ†ÙÙŠØ° (5 Ø£ÙŠØ§Ù…)
4. Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© (2 Ø£ÙŠØ§Ù…)
5. Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚ (1 ÙŠÙˆÙ…)

Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù†Ø¬Ø§Ø­:
- Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
- Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠ
- Ø¬ÙˆØ¯Ø© Ø§Ù„ØªÙ†ÙÙŠØ°
"""
        
        logger.info(f"Goal expanded: {goal_data.goal_text}")
        
        return {
            "success": True,
            "message": f"ğŸ¯ ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù: {goal_data.goal_text}",
            "type": "goal_expanded",
            "ai_response": ai_response,
            "ai_source": "openai" if ai_response else "fallback"
        }
        
    except Exception as e:
        logger.error(f"Error expanding goal: {e}")
        return {
            "success": False,
            "message": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù",
            "error": str(e)
        }

# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
@app.post("/digests/manager")
async def send_manager_digest(data: Dict[str, str]):
    """Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ Ù„Ù„Ù…Ø¯ÙŠØ±"""
    manager_email = data.get("manager_email", "manager@d10.sa")
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    team_tasks = [t for t in tasks_storage if t["status"] == "open"]
    team_kpis = kpis_storage
    
    content = f"""
    <h2>ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ - {datetime.now().strftime('%Y-%m-%d')}</h2>
    <p>Ù…Ø±Ø­Ø¨Ø§Ù‹ {manager_email.split('@')[0]}ØŒ</p>
    <p>Ø¥Ù„ÙŠÙƒ Ù…Ù„Ø®Øµ Ø£Ø¯Ø§Ø¡ ÙØ±ÙŠÙ‚Ùƒ Ø§Ù„ÙŠÙˆÙ…:</p>
    
    <h3>ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡</h3>
    <ul>
        <li>Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {len(team_tasks)}</li>
        <li>Ø¥Ø¬Ù…Ø§Ù„ÙŠ KPIs Ø§Ù„Ù…Ø³Ø¬Ù„Ø©: {len(team_kpis)}</li>
    </ul>
    
    <h3>ğŸ“‹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©</h3>
    <p>Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© Ù„ÙØ±ÙŠÙ‚Ùƒ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù….</p>
    
    <h3>ğŸ’¡ ØªÙˆØµÙŠØ§Øª</h3>
    <p>Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø°ÙŠÙ† ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù… Ø¥Ø¶Ø§ÙÙŠ.</p>
    """
    
    logger.info(f"Manager digest sent to {manager_email}")
    
    return {
        "sent": True,
        "preview": f"ØªÙ‚Ø±ÙŠØ± ÙŠÙˆÙ…ÙŠ Ù„Ù€ {manager_email} - Ù…Ù„Ø®Øµ Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙØ±ÙŠÙ‚",
        "recipients": [manager_email],
        "content": content
    }

# Ù…Ø³Ø§Ø±Ø§Øª Slack
@app.post("/slack/mock")
async def slack_mock(data: SlackMock):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø±Ø³Ø§Ø¦Ù„ Slack"""
    text = data.text
    user = data.user
    
    if text.startswith("Ù…Ù‡Ù…Ø©:"):
        task_title = text.replace("Ù…Ù‡Ù…Ø©:", "").strip()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©
        task = {
            "id": f"slack_task_{len(tasks_storage) + 1}",
            "title": task_title,
            "assignee_email": f"{user}@slack.local",
            "due_date": "2025-09-20",
            "status": "open",
            "source": "slack",
            "created_at": datetime.now().isoformat()
        }
        tasks_storage.append(task)
        
        logger.info(f"Slack task created: {task['id']}")
        
        return {
            "success": True,
            "message": f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©: {task_title}",
            "type": "task_created",
            "task_id": task["id"]
        }
        
    elif text.startswith("Ù‡Ø¯Ù:"):
        goal_text = text.replace("Ù‡Ø¯Ù:", "").strip()
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI Ù„ØªÙÙƒÙŠÙƒ Ø§Ù„Ù‡Ø¯Ù
        goal_data = GoalExpand(
            goal_text=goal_text,
            timeline="Ø£Ø³Ø¨ÙˆØ¹ÙŠÙ†",
            available_departments="sales,marketing,tech,sondos"
        )
        
        result = await expand_goal(goal_data)
        
        return {
            "success": True,
            "message": f"ğŸ¯ ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù: {goal_text}",
            "type": "goal_expanded",
            "ai_response": result.get("ai_response", ""),
            "ai_source": result.get("ai_source", "unknown")
        }
        
    else:
        return {
            "success": True,
            "message": "Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:\n- Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ø§Ù…: Ø§ÙƒØªØ¨ 'Ù…Ù‡Ù…Ø©: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‡Ù…Ø©'\n- ØªÙÙƒÙŠÙƒ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù: Ø§ÙƒØªØ¨ 'Ù‡Ø¯Ù: ÙˆØµÙ Ø§Ù„Ù‡Ø¯Ù'",
            "type": "help"
        }

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Siyadah Ops AI - Ø§Ù„Ù†Ø³Ø®Ø© Ù…Ø¹ OpenAI Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ...")
    print("ğŸŒ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ØªØ§Ø­ Ø¹Ù„Ù‰: http://127.0.0.1:8003")
    print("ğŸ“š Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰: http://127.0.0.1:8003/docs")
    print("ğŸ”§ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù€ Prompts: http://127.0.0.1:8003/prompts/coach/edit")
    print("ğŸ¤– OpenAI: Ù…ØªØµÙ„ ÙˆÙ…Ø¬Ù‡Ø²")
    print("\n" + "="*50)
    
    uvicorn.run(app, host="127.0.0.1", port=8003, reload=False)
